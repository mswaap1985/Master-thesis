\chapter{Threats To Validity}\label{sec:threats}

\todo{Report about each type of threat to the validity of the experiment, according to the classification framework proposed by Wohlin \etal \cite{wohlin12}.
https://arxiv.org/ftp/arxiv/papers/2004/2004.06183.pdf
}

\section{Internal Validity}
Within this qualitative research semi-structured interviews are used to collect data. Firstly, this method is chosen because the subjects are experts in their fields of expertise, namely personal identity. Limiting them to a questionnaire or structured interview would not provide unexpected and new information or insights in their field of expertise. Secondly, the use data gathering techniques like unstructured interviews could result in an unlimited stream of information and history. Blandford \etal \cite{Blandford2016QualitativeHR} define that semi-structured interviews “inevitably bring in the interests of the researcher as well as the participant.”. 
\par
It’s needed to acknowledge the bias introduced by the researcher. Blandford \etal \cite{Blandford2016QualitativeHR} define the shaping of data gathering by a researcher as follows: “The researcher is shaping the conversation and the data that is gathered, and the extent of that shaping should be recognized and reported transparently and unapologetically.” The relationship between researcher and subjects is as colleagues within a Dutch government body
\section{External Validity}
\section{Construct Validity}
\section{Conclusion Validity}

\todo{Voorbeeld:The main threats to the internal validity are: learning effect, subjects’ experience,
information exchange among participants, author’s bias, author influence, the order of
methods in the training and understandability of the documents. Two experimental
objects were used to deal with the learning effect, such as ensuring that each subject
applied each method in a different system and considering all the possible
combinations of both the method order and the experimental objects. There were no
differences on the subjects’ experience since none of them had experience in
architecture evaluations. The subjects were introduced to the tasks and the problems
they would have to solve via their participation in training sessions on both methods.
Information exchange was alleviated by using different experimental objects at the
same time, and monitoring the subjects while they performed the tasks. Since the
experiment was designed to take place in two sessions, the subjects might have been
able to exchange information during the time between the sessions, but this was
alleviated by asking the participants to return the material at the end of each session.
The author’s bias in this experiment may have influenced the results since the training
sessions were conducted by an author of the method. The author influence was
alleviated by not disclosing to the subjects the authorship of the QuaDAI method. The
order of methods during the training and experimental sessions could have also
influenced the results since it was the same in each session. This issue will be
investigated in future replications of this experiment. The understandability of the
material was alleviated by clearing up all the misunderstandings that appeared in the
pilot experiment and experimental sessions.
The main threat to external validity is the representativeness of the results. The
representativeness of the results might be affected by the evaluation design and the
participant context selected. The evaluation design might have had an impact on the
results owing to the kind of architectural models and quality attributes to be
evaluated. We selected two different architectures, from two different domains, two
different NFRs and four different patterns for each experimental object. The
experiment was conducted with students with no experience in architectural
evaluations, and who received only limited training on the evaluation methods.
However, since they were final year students they can be considered as novice users
of architectural evaluation methods, and the next generation of practitioners [24]. The
results could thus be considered as representative of novice evaluators.
The main threats to the construct validity are the measures used to quantify the
dependent variables. Effectiveness was measured using the Euclidean distance which
has commonly been used to measure the goodness of a solution with regard to a set of
opposed NFRs with different purposes [12] [33]. The subjective variables are based
on the Technology Acceptance Method (TAM) [13], a well-known and empirically
validated model for the evaluation of information technologies. The reliability of the
questionnaire was tested by applying the Cronbach test. Questions related to PEOU,
PU and ITU obtained a Cronbach’s alpha of 0.824, 0.870 and 0.831, which is higher
than the acceptable minimum (0.70) [27]. The main threat to the conclusion validity
is the validity of the statistical tests applied. This threat was alleviated by applying a }